{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from imp import reload\n",
    "import preprocessing; reload(preprocessing)\n",
    "\n",
    "from preprocessing import ImageProcessor, DatasetProcessor\n",
    "from preprocessing import Analytics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "except ImportError:\n",
    "    from sklearn.model_selection import train_test_split  \n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#DatasetProcessor.file_train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Const params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "SEED = 42\n",
    "TRAIN_PATH = '../input/train/'\n",
    "VALIDATE_PATH = '../input/validation/'\n",
    "\n",
    "random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wnids_train = DatasetProcessor.get_dataset_wnids(dataset_dir=TRAIN_PATH)\n",
    "wnids_test = DatasetProcessor.get_dataset_wnids(dataset_dir=VALIDATE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wnid_to_lable = DatasetProcessor.get_wnid_table()\n",
    "\n",
    "train = DatasetProcessor.get_dataset_paths_from_wnid(wnids_train, dataset_path=TRAIN_PATH)\n",
    "test = DatasetProcessor.get_dataset_paths_from_wnid(wnids_test, dataset_path=VALIDATE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Transform data and create consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wnid_to_one_hot = DatasetProcessor.wnid_to_one_hot(wnids_train)\n",
    "lables = sorted(wnid_to_one_hot.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train = DatasetProcessor.paths_to_one_hot(train, wnid_to_one_hot)\n",
    "y_test = DatasetProcessor.paths_to_one_hot(test, wnid_to_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = len(train)\n",
    "TEST_SIZE = len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exploritory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print ('Train size:', len(train))\n",
    "print ('Test size:', len(test))\n",
    "print ('Class number:', len(wnids_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wnids_train = sorted(wnids_train)\n",
    "print(wnids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classes = [wnid_to_lable[wnid] for wnid in wnids_train]\n",
    "print ('Lables:', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ImageProcessor.set_image_size(10, 5)\n",
    "class_distribution = Analytics.extract_class_distribution(train)\n",
    "classes = map(lambda x: wnid_to_lable[x], class_distribution.keys())\n",
    "\n",
    "plt.bar(range(len(class_distribution)), class_distribution.values(), align='center')\n",
    "plt.xticks(range(len(class_distribution)), classes, rotation='vertical')\n",
    "plt.title('Class Distribution')\n",
    "plt.ylabel('Number of images')\n",
    "plt.xlabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ImageProcessor.set_image_size(20, 34, 100)\n",
    "\n",
    "for i in range(1, 28):\n",
    "    plt.subplot(9, 3, i)\n",
    "    \n",
    "    random_index = np.random.randint(0, len(train))\n",
    "    image_path = train[random_index]\n",
    "    image = ImageProcessor.get_image(image_path)\n",
    "\n",
    "    processed_image = ImageProcessor.get_processed_image(image, size=image_size)\n",
    "    \n",
    "    wnid = DatasetProcessor.extract_wnid(image_path)\n",
    "    plt.title(wnid_to_lable[wnid])\n",
    "    \n",
    "    plt.imshow(processed_image)\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data jittering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(train))\n",
    "image_path = train[random_index]\n",
    "\n",
    "wnid = DatasetProcessor.extract_wnid(image_path)\n",
    "print(wnid_to_lable[wnid])\n",
    "\n",
    "img = ImageProcessor.get_image(image_path)  # this is a PIL image\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Baseline convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import fileupload\n",
    "#fileupload.nbinstall()\n",
    "\n",
    "# Run in keras docker\n",
    "# jupyter nbextension enable --py --sys-prefix widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Convolution2D, BatchNormalization, Input\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.models import model_from_json, Model, Sequential\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../input/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '../input/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=14929 // batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1649  // batch_size,\n",
    "        verbose=0,\n",
    "        callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "model.save_weights('shallow_model.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Deeper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../input/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        classes=classes\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '../input/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        classes=classes\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=14929 // batch_size,\n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1649  // batch_size,\n",
    "        verbose=0,\n",
    "        callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "model.save_weights('deeper_model.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Deeper model + batch norm + agressive jittering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../input/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '../input/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=14929 // batch_size,\n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1649  // batch_size,\n",
    "        verbose=0,\n",
    "        callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "model.save_weights('batch_norm.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50, InceptionV3, Xception\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.optimizers import Adam, Adamax, RMSprop\n",
    "from keras.activations import relu, elu, tanh, sigmoid\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, log_loss, accuracy_score\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_DIM = 224\n",
    "INPUT_TENSOR = Input(shape=(IMG_DIM, IMG_DIM, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(input_tensor=INPUT_TENSOR, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "\n",
    "top_model.add(Dense(512))\n",
    "top_model.add(BatchNormalization())\n",
    "top_model.add(Activation(elu))\n",
    "top_model.add(Dropout(0.3))\n",
    "\n",
    "top_model.add(Dense(512))\n",
    "top_model.add(BatchNormalization())\n",
    "top_model.add(Activation(elu))\n",
    "\n",
    "top_model.add(Dense(15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Model(input= base_model.input, output= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "TRAIN_STEPS = math.ceil(TRAIN_SIZE / batch_size)\n",
    "VALIDATION_STEPS = math.ceil(TEST_SIZE / batch_size)\n",
    "\n",
    "print(TRAIN_STEPS, VALIDATION_STEPS)\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../input/train',  # this is the target directory\n",
    "        target_size=(IMG_DIM, IMG_DIM),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '../input/validation',\n",
    "        target_size=(IMG_DIM, IMG_DIM),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model = load_model('FineTunedResNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=TRAIN_STEPS,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        verbose=0,\n",
    "        callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "# Inception v3\n",
    "# 0.001\n",
    "# 100% 5/5 [1:07:17<00:00, 808.72s/it]\n",
    "# [loss: 0.920, acc: 0.662, val_loss: 0.609, val_acc: 0.763] 100% 234/234 [13:47<00:00, 31.12s/it]\n",
    "# [loss: 0.722, acc: 0.718, val_loss: 0.526, val_acc: 0.787] 100% 234/234 [13:21<00:00, 27.04s/it]\n",
    "# [loss: 0.679, acc: 0.736, val_loss: 0.476, val_acc: 0.790] 100% 234/234 [13:22<00:00, 27.15s/it]\n",
    "# [loss: 0.651, acc: 0.743, val_loss: 0.489, val_acc: 0.787] 100% 234/234 [13:22<00:00, 27.20s/it]\n",
    "# [loss: 0.634, acc: 0.751, val_loss: 0.481, val_acc: 0.793] 100% 234/234 [13:23<00:00, 27.19s/it]\n",
    "\n",
    "# 0.0001\n",
    "# [loss: 0.604, acc: 0.763, val_loss: 0.454, val_acc: 0.808] 100% 467/467 [14:48<00:00, 27.96s/it]\n",
    "# [loss: 0.599, acc: 0.769, val_loss: 0.455, val_acc: 0.815] 100% 467/467 [14:34<00:00, 27.90s/it]\n",
    "# [loss: 0.580, acc: 0.775, val_loss: 0.456, val_acc: 0.802] 100% 467/467 [14:38<00:00, 26.89s/it]\n",
    "# [loss: 0.568, acc: 0.775, val_loss: 0.438, val_acc: 0.820] 100% 467/467 [14:33<00:00, 27.18s/it]\n",
    "# [loss: 0.568, acc: 0.776, val_loss: 0.428, val_acc: 0.812] 100% 467/467 [14:35<00:00, 27.17s/it]\n",
    "\n",
    "# 0.00001\n",
    "# [loss: 0.558, acc: 0.782, val_loss: 0.438, val_acc: 0.817] 100% 467/467 [14:41<00:00, 28.33s/it]\n",
    "# [loss: 0.556, acc: 0.784, val_loss: 0.439, val_acc: 0.817] 100% 467/467 [14:49<00:00, 27.29s/it]\n",
    "# [loss: 0.547, acc: 0.785, val_loss: 0.411, val_acc: 0.825] 100% 467/467 [15:03<00:00, 28.53s/it]\n",
    "# [loss: 0.554, acc: 0.782, val_loss: 0.433, val_acc: 0.817] 100% 467/467 [16:03<00:00, 28.12s/it]\n",
    "# [loss: 0.554, acc: 0.786, val_loss: 0.424, val_acc: 0.824] 100% 467/467 [15:31<00:00, 27.48s/it]\n",
    "\n",
    "# ResNet50, adam 0.001\n",
    "# [loss: 0.844, acc: 0.690, val_loss: 2.858, val_acc: 0.246] 100% 467/467 [19:51<00:00, 42.98s/it]\n",
    "# [loss: 0.653, acc: 0.746, val_loss: 0.733, val_acc: 0.709] 100% 467/467 [19:48<00:00, 42.66s/it]\n",
    "# [loss: 0.589, acc: 0.768, val_loss: 0.564, val_acc: 0.772] 100% 467/467 [19:51<00:00, 42.12s/it]\n",
    "# [loss: 0.571, acc: 0.777, val_loss: 0.501, val_acc: 0.793] 100% 467/467 [19:35<00:00, 42.21s/it]\n",
    "# [loss: 0.549, acc: 0.783, val_loss: 0.481, val_acc: 0.800] 100% 467/467 [19:36<00:00, 42.19s/it]\n",
    "# [loss: 0.528, acc: 0.789, val_loss: 0.466, val_acc: 0.809] 100% 467/467 [19:46<00:00, 42.72s/it]\n",
    "# [loss: 0.514, acc: 0.797, val_loss: 0.449, val_acc: 0.810] 100% 467/467 [20:12<00:00, 42.76s/it]\n",
    "\n",
    "# 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model.save('ResNet50.h5')\n",
    "#model = load_model('InceptionV3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "metric_validation_generator = test_datagen.flow_from_directory(\n",
    "        '../input/validation',\n",
    "        target_size=(IMG_DIM, IMG_DIM),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        classes=lables)\n",
    "\n",
    "metric_validation_generator.reset()\n",
    "y_pred = model.predict_generator(metric_validation_generator, VALIDATION_STEPS)\n",
    "y_pred = DatasetProcessor.softmax_predictions_to_one_hot(y_pred)\n",
    "\n",
    "print(y_pred.shape)\n",
    "\n",
    "y_test = []\n",
    "metric_validation_generator.reset()\n",
    "for validation_touple in metric_validation_generator:\n",
    "    X_test_batch, y_pred_batch = validation_touple\n",
    "    y_test.extend(y_pred_batch)\n",
    "    \n",
    "    if metric_validation_generator.batch_index == 0:\n",
    "        break\n",
    "    \n",
    "y_test = np.array(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "acc = accuracy_score(y_test, y_pred, 'macro')\n",
    "\n",
    "print('Recall:', recall)\n",
    "print('Precison:', precision)\n",
    "print('F1:', f1)\n",
    "print('Acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_num = [15, 14, 13, 12, 11, 10, 9, 8, 7]\n",
    "acc = [0.835, 0.832, 0.866, 0.892, 0.884, 0.888, 0.875, 0.872,  0.871]\n",
    "\n",
    "ImageProcessor.set_image_size(13, 5, 72)\n",
    "plt.plot(class_num, acc)\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "plt.title('Model accuracy with different class numbers')\n",
    "plt.xlabel('Class number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('model_acc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred_categorical = DatasetProcessor.from_one_hot_to_categorical(y_pred)\n",
    "y_test_categorical = DatasetProcessor.from_one_hot_to_categorical(y_test)\n",
    "    \n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test_categorical, y_pred_categorical)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "ImageProcessor.set_image_size(15, 15, 90)\n",
    "classes = [wnid_to_lable[wnid] for wnid in wnids_train]\n",
    "Analytics.plot_confusion_matrix(cnf_matrix, classes=list(classes), title='Confusion matrix')\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(150,150,3))\n",
    "base_model = applications.VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "\n",
    "top_model.add(Dense(32))\n",
    "top_model.add(BatchNormalization())\n",
    "top_model.add(Activation('relu'))\n",
    "\n",
    "top_model.add(Dense(64))\n",
    "top_model.add(BatchNormalization())\n",
    "top_model.add(Activation('relu'))\n",
    "\n",
    "top_model.add(Dense(15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../input/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '../input/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=14929 // batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1649  // batch_size,\n",
    "        verbose=0,\n",
    "        callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "model.save_weights('vgg16.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pretrained convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = applications.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        '../input/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "        shuffle=False)\n",
    "\n",
    "# the predict_generator method returns the output of a model, given\n",
    "# a generator that yields batches of numpy data\n",
    "bottleneck_features_train = model.predict_generator(generator, 14929)\n",
    "# save the output as a Numpy array\n",
    "np.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        '../input/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "bottleneck_features_validation = model.predict_generator(generator, 1649)\n",
    "np.save(open('bottleneck_features_validation.npy', 'w'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "train_labels = np.array([0] * 1000 + [1] * 1000)\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "validation_labels = np.array([0] * 400 + [1] * 400)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
