\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{samuel_studies_1959}
\citation{cifar}
\citation{imagenet}
\citation{kaggle}
\citation{krizhevsky_imagenet_2012,simonyan_very_2014,szegedy_going_2015,he_deep_2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{se:introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Research context}{2}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Definitions and notation}{2}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Image representation}{2}{subsection.2.1.1}}
\newlabel{eq_2d_matrix}{{2.1}{2}{Image representation}{equation.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces RGB image with 9 pixels represented as a 3 dimensional matrix\relax }}{3}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:image_matrix}{{2.1}{3}{RGB image with 9 pixels represented as a 3 dimensional matrix\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Gradient}{3}{subsection.2.1.2}}
\newlabel{se:gradient}{{2.1.2}{3}{Gradient}{subsection.2.1.2}{}}
\newlabel{eq:gradient}{{2.2}{3}{Gradient}{equation.2.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Activation functions}{3}{subsection.2.1.3}}
\newlabel{se:activation_functions}{{2.1.3}{3}{Activation functions}{subsection.2.1.3}{}}
\newlabel{eq:sigmoid}{{2.3}{3}{Activation functions}{equation.2.1.3}{}}
\newlabel{eq:tanh}{{2.4}{3}{Activation functions}{equation.2.1.4}{}}
\newlabel{fig:sigmoid}{{2.2a}{4}{$simgoid$\relax }{figure.caption.3}{}}
\newlabel{sub@fig:sigmoid}{{a}{4}{$simgoid$\relax }{figure.caption.3}{}}
\newlabel{fig:tanh}{{2.2b}{4}{$tanh$\relax }{figure.caption.3}{}}
\newlabel{sub@fig:tanh}{{b}{4}{$tanh$\relax }{figure.caption.3}{}}
\newlabel{fig:relu}{{2.2c}{4}{$relu$\relax }{figure.caption.3}{}}
\newlabel{sub@fig:relu}{{c}{4}{$relu$\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Nonliear activation functions\relax }}{4}{figure.caption.3}}
\newlabel{fig:subfig1.a.4}{{2.2}{4}{Nonliear activation functions\relax }{figure.caption.3}{}}
\newlabel{eq:relu}{{2.5}{4}{Activation functions}{equation.2.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Metrics}{4}{subsection.2.1.4}}
\newlabel{se:metrics}{{2.1.4}{4}{Metrics}{subsection.2.1.4}{}}
\newlabel{eq:accuracy}{{2.6}{4}{Metrics}{equation.2.1.6}{}}
\newlabel{eq:precision}{{2.7}{4}{Metrics}{equation.2.1.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Confusion matrix\relax }}{5}{table.caption.4}}
\newlabel{tb:confusion_matrix}{{2.1}{5}{Confusion matrix\relax }{table.caption.4}{}}
\newlabel{eq:recall}{{2.8}{5}{Metrics}{equation.2.1.8}{}}
\newlabel{eq:f1score}{{2.9}{5}{Metrics}{equation.2.1.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Data}{5}{subsection.2.1.5}}
\newlabel{se:data}{{2.1.5}{5}{Data}{subsection.2.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Machine learning}{6}{section.2.2}}
\newlabel{se:machine_learning}{{2.2}{6}{Machine learning}{section.2.2}{}}
\newlabel{eq:hypotesis}{{2.10}{6}{Machine learning}{equation.2.2.10}{}}
\newlabel{eq:model}{{2.11}{6}{Machine learning}{equation.2.2.11}{}}
\newlabel{eq:error_function}{{2.12}{6}{Machine learning}{equation.2.2.12}{}}
\newlabel{eq:optimization_function}{{2.13}{6}{Machine learning}{equation.2.2.13}{}}
\newlabel{eq:regression_def}{{2.14}{6}{Machine learning}{equation.2.2.14}{}}
\newlabel{eq:classification_def}{{2.15}{6}{Machine learning}{equation.2.2.15}{}}
\citation{srivastava_dropout:_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Performance of a model by the number of epochs using training and test set\relax }}{7}{figure.caption.5}}
\newlabel{fig:overfitting}{{2.3}{7}{Performance of a model by the number of epochs using training and test set\relax }{figure.caption.5}{}}
\citation{mcculloch_logical_1943}
\citation{kleene_representation_1951}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Supervised and unsupervised learning}{8}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Artificial neural network (ANN)}{8}{subsection.2.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Neuron cell in a brain.\relax }}{9}{figure.caption.6}}
\newlabel{fig:neuron}{{2.4}{9}{Neuron cell in a brain.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Artificial neuron cell.\relax }}{9}{figure.caption.7}}
\newlabel{fig:ann_neuron}{{2.5}{9}{Artificial neuron cell.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Feed-forward neural network\relax }}{10}{figure.caption.8}}
\newlabel{fig:ann}{{2.6}{10}{Feed-forward neural network\relax }{figure.caption.8}{}}
\newlabel{eq:neuron_net_output}{{2.16}{10}{Artificial neural network (ANN)}{equation.2.2.16}{}}
\newlabel{eq:neuron_output}{{2.17}{10}{Artificial neural network (ANN)}{equation.2.2.17}{}}
\citation{krizhevsky_imagenet_2012,simonyan_very_2014,szegedy_going_2015,he_deep_2016}
\citation{hubel_receptive_1968}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Deep learning}{11}{section.2.3}}
\newlabel{se:deep_learning}{{2.3}{11}{Deep learning}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Convolutional neural Network (CNN / ConvNet)}{11}{subsection.2.3.1}}
\citation{fukushima_neocognitron:_1982,eckmiller_hierarchical_1989}
\citation{krizhevsky_imagenet_2012,simonyan_very_2014,szegedy_going_2015,he_deep_2016}
\citation{simonyan_very_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces 3D structure of a convolutional filter (on the left painted in pink is the input - image - and the blue rectangle with circles is a filter)\relax }}{12}{figure.caption.9}}
\newlabel{fig:conv}{{2.7}{12}{3D structure of a convolutional filter (on the left painted in pink is the input - image - and the blue rectangle with circles is a filter)\relax }{figure.caption.9}{}}
\citation{simonyan_very_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces A 3x3 kernel (filter) convolving and input to generate an output\relax }}{13}{figure.caption.10}}
\newlabel{fig:conv1}{{2.8}{13}{A 3x3 kernel (filter) convolving and input to generate an output\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Representation of filters through the CNN\relax }}{13}{figure.caption.11}}
\newlabel{fig:filter}{{2.9}{13}{Representation of filters through the CNN\relax }{figure.caption.11}{}}
\citation{srivastava_dropout:_2014}
\citation{ioffe_batch_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Max pooling a 4x4 input to 2x2\relax }}{14}{figure.caption.12}}
\newlabel{fig:pool}{{2.10}{14}{Max pooling a 4x4 input to 2x2\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Typical modern CNN\relax }}{14}{figure.caption.13}}
\newlabel{fig:cnn}{{2.11}{14}{Typical modern CNN\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Dropout}{14}{subsection.2.3.2}}
\newlabel{se:dropout}{{2.3.2}{14}{Dropout}{subsection.2.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces An example of the dropout technique\relax }}{15}{figure.caption.14}}
\newlabel{fig:dropout}{{2.12}{15}{An example of the dropout technique\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces An example of the original - unprocessed - image in $X_{train}$\relax }}{15}{figure.caption.15}}
\newlabel{fig:data_augmentation_figure}{{2.13}{15}{An example of the original - unprocessed - image in $X_{train}$\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Data augmentation}{15}{subsection.2.3.3}}
\newlabel{se:data_augmentation}{{2.3.3}{15}{Data augmentation}{subsection.2.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Example of data augmented images based on the original image \ref  {fig:data_augmentation_figure}\relax }}{16}{figure.caption.16}}
\newlabel{fig:data_augmentation}{{2.14}{16}{Example of data augmented images based on the original image \ref {fig:data_augmentation_figure}\relax }{figure.caption.16}{}}
\citation{kingma_adam:_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces An example of local and global maximum and minimum in a function\relax }}{17}{figure.caption.18}}
\newlabel{fig:local_and_global_function_values}{{2.15}{17}{An example of local and global maximum and minimum in a function\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Backpropagation}{17}{subsection.2.3.4}}
\newlabel{se:backprop}{{2.3.4}{17}{Backpropagation}{subsection.2.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Gradient descent}{17}{section*.17}}
\newlabel{eq:gradient_descent}{{2.18}{17}{Gradient descent}{equation.2.3.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces An example of gradient descent converging to global minimum in a 2D space (function with two variables)\relax }}{18}{figure.caption.19}}
\newlabel{fig:local_and_global_function_values}{{2.16}{18}{An example of gradient descent converging to global minimum in a 2D space (function with two variables)\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{Stochastic gradient descent}{18}{section*.20}}
\newlabel{se:stochastic_gd}{{2.3.4}{18}{Stochastic gradient descent}{section*.20}{}}
\citation{clevert_fast_2015,xu_empirical_2015,he_delving_2015}
\citation{he_deep_2016}
\@writefile{toc}{\contentsline {subsubsection}{Optimization target}{19}{section*.21}}
\newlabel{eq:softmax}{{2.19}{19}{Optimization target}{equation.2.3.19}{}}
\newlabel{eq:cross_entropy_loss}{{2.20}{19}{Optimization target}{equation.2.3.20}{}}
\newlabel{eq:cross_entropy_graidnet}{{2.21}{19}{Optimization target}{equation.2.3.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Vanishing gradient}{19}{subsection.2.3.5}}
\newlabel{se:vanishing_gradient}{{2.3.5}{19}{Vanishing gradient}{subsection.2.3.5}{}}
\citation{ioffe_batch_2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Batch normalization}{20}{subsection.2.3.6}}
\newlabel{se:batch_norm}{{2.3.6}{20}{Batch normalization}{subsection.2.3.6}{}}
\citation{he_deep_2016}
\citation{tensorflow}
\citation{caffe}
\citation{pytorch}
\citation{keras}
\citation{theano}
\citation{cntk}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Model}{21}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{se:model}{{3}{21}{Model}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Implementation}{21}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Keras}{21}{subsection.3.1.1}}
\newlabel{se:keras}{{3.1.1}{21}{Keras}{subsection.3.1.1}{}}
\citation{he_deep_2016,simonyan_very_2014,szegedy_going_2015}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.1}Keras high level API example}{22}{lstlisting.3.1}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces CNN architecture performance comparison on ImageNet dataset\relax }}{23}{table.caption.22}}
\newlabel{tb:CNN_architecutre_performance}{{3.1}{23}{CNN architecture performance comparison on ImageNet dataset\relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Architecture}{23}{subsection.3.1.2}}
\newlabel{se:architecture}{{3.1.2}{23}{Architecture}{subsection.3.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The residual layer (module) - the core building block of the ResNet \relax }}{24}{figure.caption.23}}
\newlabel{fig:residual_layer}{{3.1}{24}{The residual layer (module) - the core building block of the ResNet \relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Pretrained parameters}{24}{subsection.3.1.3}}
\newlabel{se:pretrained_parameters}{{3.1.3}{24}{Pretrained parameters}{subsection.3.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A comparison of two popular CNN architectures - ResNet and VGG \relax }}{25}{figure.caption.24}}
\newlabel{fig:vgg_resnet_comparison}{{3.2}{25}{A comparison of two popular CNN architectures - ResNet and VGG \relax }{figure.caption.24}{}}
\citation{imagenet}
\citation{kingma_adam:_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Inception v3's inception module\relax }}{26}{figure.caption.25}}
\newlabel{fig:inception_module}{{3.3}{26}{Inception v3's inception module\relax }{figure.caption.25}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.2}Creating a custom pretrained ResNet on the ImageNet dataset}{26}{lstlisting.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Improving generalization}{27}{subsection.3.1.4}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.3}Data augmentation of the input dataset (images)}{27}{lstlisting.3.3}}
\citation{imagenet}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Data}{29}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}ImageNet}{29}{section.4.1}}
\newlabel{se:imagenet}{{4.1}{29}{ImageNet}{section.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Dataset}{29}{subsection.4.1.1}}
\newlabel{se:dataset}{{4.1.1}{29}{Dataset}{subsection.4.1.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces ImageNet statistics\relax }}{30}{table.caption.27}}
\newlabel{tb:imagenet_statistics}{{4.1}{30}{ImageNet statistics\relax }{table.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Typical ImageNet image, class herbivore\relax }}{31}{figure.caption.26}}
\newlabel{fig:typical_imagenet_example}{{4.1}{31}{Typical ImageNet image, class herbivore\relax }{figure.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Dataset statistics\relax }}{31}{table.caption.29}}
\newlabel{tb:dataset_statistics}{{4.2}{31}{Dataset statistics\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Preprocessing}{31}{subsection.4.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Class distribution of training data\relax }}{32}{figure.caption.28}}
\newlabel{fig:training_set_class_distributon}{{4.2}{32}{Class distribution of training data\relax }{figure.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces List of all 15 species used to train the model\relax }}{33}{table.caption.30}}
\newlabel{tb:species_list}{{4.3}{33}{List of all 15 species used to train the model\relax }{table.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Species}{33}{section.4.2}}
\newlabel{se:species}{{4.2}{33}{Species}{section.4.2}{}}
\newlabel{fig:ursus_thibetanus}{{4.3a}{35}{Ursus thibetanus\relax }{figure.caption.31}{}}
\newlabel{sub@fig:ursus_thibetanus}{{a}{35}{Ursus thibetanus\relax }{figure.caption.31}{}}
\newlabel{fig:sphyrna_tiburo}{{4.3b}{35}{Sphyrna tiburo\relax }{figure.caption.31}{}}
\newlabel{sub@fig:sphyrna_tiburo}{{b}{35}{Sphyrna tiburo\relax }{figure.caption.31}{}}
\newlabel{fig:hippodamia_convergens}{{4.3c}{35}{Hippodamia convergens\relax }{figure.caption.31}{}}
\newlabel{sub@fig:hippodamia_convergens}{{c}{35}{Hippodamia convergens\relax }{figure.caption.31}{}}
\newlabel{fig:ursus_maritimus}{{4.3d}{35}{Ursus maritimus\relax }{figure.caption.31}{}}
\newlabel{sub@fig:ursus_maritimus}{{d}{35}{Ursus maritimus\relax }{figure.caption.31}{}}
\newlabel{fig:vulpes_fulva}{{4.3e}{35}{Vulpes fulva\relax }{figure.caption.31}{}}
\newlabel{sub@fig:vulpes_fulva}{{e}{35}{Vulpes fulva\relax }{figure.caption.31}{}}
\newlabel{fig:cygnus_buccinator}{{4.3f}{35}{Cygnus buccinator\relax }{figure.caption.31}{}}
\newlabel{sub@fig:cygnus_buccinator}{{f}{35}{Cygnus buccinator\relax }{figure.caption.31}{}}
\newlabel{fig:adalia_bipunctata}{{4.3g}{35}{Adalia bipunctata\relax }{figure.caption.31}{}}
\newlabel{sub@fig:adalia_bipunctata}{{g}{35}{Adalia bipunctata\relax }{figure.caption.31}{}}
\newlabel{fig:rodolia_cardinalis}{{4.3h}{35}{Rodolia cardinalis\relax }{figure.caption.31}{}}
\newlabel{sub@fig:rodolia_cardinalis}{{h}{35}{Rodolia cardinalis\relax }{figure.caption.31}{}}
\newlabel{fig:diomedea_exulans}{{4.3i}{35}{Diomedea exulans\relax }{figure.caption.31}{}}
\newlabel{sub@fig:diomedea_exulans}{{i}{35}{Diomedea exulans\relax }{figure.caption.31}{}}
\newlabel{fig:epilachna_varivestis}{{4.3j}{35}{Epilachna varivestis\relax }{figure.caption.31}{}}
\newlabel{sub@fig:epilachna_varivestis}{{j}{35}{Epilachna varivestis\relax }{figure.caption.31}{}}
\newlabel{fig:canis_rufus}{{4.3k}{35}{Canis rufus\relax }{figure.caption.31}{}}
\newlabel{sub@fig:canis_rufus}{{k}{35}{Canis rufus\relax }{figure.caption.31}{}}
\newlabel{fig:triaenodon_obseus}{{4.3l}{35}{Triaenodon obseus\relax }{figure.caption.31}{}}
\newlabel{sub@fig:triaenodon_obseus}{{l}{35}{Triaenodon obseus\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Examples of species with a randomly picked image from the input dataset\relax }}{35}{figure.caption.31}}
\newlabel{fig:specis_image_examples}{{4.3}{35}{Examples of species with a randomly picked image from the input dataset\relax }{figure.caption.31}{}}
\citation{docker}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{36}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{se:results}{{5}{36}{Results}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Hardware and software}{36}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}ResNet-50 and Inception v3 comparison}{36}{section.5.2}}
\newlabel{se:resnet_vs_inception}{{5.2}{36}{ResNet-50 and Inception v3 comparison}{section.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Hardware specifications\relax }}{36}{table.caption.32}}
\newlabel{tb:hardware_specifications}{{5.1}{36}{Hardware specifications\relax }{table.caption.32}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Software specifications\relax }}{37}{table.caption.33}}
\newlabel{tb:software_specifications}{{5.2}{37}{Software specifications\relax }{table.caption.33}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces ResNet-50 and Inception v3 architecture comparison on the validation set\relax }}{37}{table.caption.34}}
\newlabel{tb:resnet_vs_inceptionv3}{{5.3}{37}{ResNet-50 and Inception v3 architecture comparison on the validation set\relax }{table.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Performance}{37}{section.5.3}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Software specifications\relax }}{37}{table.caption.37}}
\newlabel{tb:software_specifications}{{5.4}{37}{Software specifications\relax }{table.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces ResNet50 performance on the training and validation sets\relax }}{38}{figure.caption.35}}
\newlabel{fig:resnet_performance}{{5.1}{38}{ResNet50 performance on the training and validation sets\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Inception v3 performance on the training and validation sets\relax }}{38}{figure.caption.36}}
\newlabel{fig:inceptionv3_performance}{{5.2}{38}{Inception v3 performance on the training and validation sets\relax }{figure.caption.36}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Classifier performance\relax }}{39}{table.caption.38}}
\newlabel{tb:classifier_performance}{{5.5}{39}{Classifier performance\relax }{table.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Memory footprint}{39}{section.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Confusion matrix generated on $X_{validation}$\relax }}{40}{figure.caption.39}}
\newlabel{fig:species_confusion_matrix}{{5.3}{40}{Confusion matrix generated on $X_{validation}$\relax }{figure.caption.39}{}}
\citation{yan_hd-cnn:_2015,yan_hd-cnn:_2015-1}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Model accuracy compared with different number of classes in $X_{validation}$ using the final model\relax }}{41}{figure.caption.40}}
\newlabel{fig:model_acc_class_num}{{5.4}{41}{Model accuracy compared with different number of classes in $X_{validation}$ using the final model\relax }{figure.caption.40}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces Number of parameters\relax }}{41}{table.caption.41}}
\newlabel{tb:model_params}{{5.6}{41}{Number of parameters\relax }{table.caption.41}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Future work}{41}{section.5.5}}
\newlabel{se:future_work}{{5.5}{41}{Future work}{section.5.5}{}}
\bibstyle{fer}
\bibdata{master_thesis}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{43}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{caffe}{{1}{}{{caf}}{{}}}
\bibcite{cifar}{{2}{}{{cif}}{{}}}
\bibcite{cntk}{{3}{}{{cnt}}{{}}}
\bibcite{docker}{{4}{}{{doc}}{{}}}
\bibcite{imagenet}{{5}{}{{ima}}{{}}}
\bibcite{kaggle}{{6}{}{{kag}}{{}}}
\bibcite{keras}{{7}{}{{ker}}{{}}}
\bibcite{pytorch}{{8}{}{{pyt}}{{}}}
\bibcite{tensorflow}{{9}{}{{ten}}{{}}}
\bibcite{theano}{{10}{}{{the}}{{}}}
\bibcite{clevert_fast_2015}{{11}{}{{Clevert et~al.}}{{Clevert, Unterthiner, i Hochreiter}}}
\bibcite{eckmiller_hierarchical_1989}{{12}{}{{Fukushima}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{44}{chapter*.42}}
\bibcite{fukushima_neocognitron:_1982}{{13}{}{{Fukushima i Miyake}}{{}}}
\bibcite{he_deep_2016}{{14}{a}{{He et~al.}}{{He, Zhang, Ren, i Sun}}}
\bibcite{he_delving_2015}{{15}{b}{{He et~al.}}{{He, Zhang, Ren, i Sun}}}
\bibcite{hubel_receptive_1968}{{16}{}{{Hubel i Wiesel}}{{}}}
\bibcite{ioffe_batch_2015}{{17}{}{{Ioffe i Szegedy}}{{}}}
\bibcite{kingma_adam:_2014}{{18}{}{{Kingma i Ba}}{{}}}
\bibcite{kleene_representation_1951}{{19}{}{{Kleene}}{{}}}
\bibcite{krizhevsky_imagenet_2012}{{20}{}{{Krizhevsky et~al.}}{{Krizhevsky, Sutskever, i Hinton}}}
\bibcite{mcculloch_logical_1943}{{21}{}{{{McCulloch} i Pitts}}{{}}}
\bibcite{samuel_studies_1959}{{22}{}{{Samuel}}{{}}}
\bibcite{simonyan_very_2014}{{23}{}{{Simonyan i Zisserman}}{{}}}
\bibcite{srivastava_dropout:_2014}{{24}{}{{Srivastava et~al.}}{{Srivastava, Hinton, Krizhevsky, Sutskever, i Salakhutdinov}}}
\bibcite{szegedy_going_2015}{{25}{}{{Szegedy et~al.}}{{Szegedy, Liu, Jia, Sermanet, Reed, Anguelov, Erhan, Vanhoucke, i Rabinovich}}}
\bibcite{xu_empirical_2015}{{26}{}{{Xu et~al.}}{{Xu, Wang, Chen, i Li}}}
\bibcite{yan_hd-cnn:_2015-1}{{27}{a}{{Yan et~al.}}{{Yan, Jagadeesh, {DeCoste}, Di, i Piramuthu}}}
\bibcite{yan_hd-cnn:_2015}{{28}{b}{{Yan et~al.}}{{Yan, Zhang, Piramuthu, Jagadeesh, {DeCoste}, Di, i Yu}}}
