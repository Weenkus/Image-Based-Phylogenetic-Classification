\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{samuel_studies_1959}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Research context}{2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Definitions and notation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Image representation}{2}}
\newlabel{eq_2d_matrix}{{2.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces RGB image with 4 pixels represented as a 3 dimensional matrix\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:image_matrix}{{2.1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Gradient}{3}}
\newlabel{eq:gradient}{{2.2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Activation functions}{3}}
\newlabel{eq:sigmoid}{{2.3}{3}}
\newlabel{eq:tanh}{{2.4}{3}}
\newlabel{eq:relu}{{2.5}{3}}
\newlabel{fig:sigmoid}{{2.2a}{4}}
\newlabel{sub@fig:sigmoid}{{a}{4}}
\newlabel{fig:tanh}{{2.2b}{4}}
\newlabel{sub@fig:tanh}{{b}{4}}
\newlabel{fig:relu}{{2.2c}{4}}
\newlabel{sub@fig:relu}{{c}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Nonliear activation functions\relax }}{4}}
\newlabel{fig:subfig1.a.4}{{2.2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Metrics}{4}}
\newlabel{eq:accuracy}{{2.6}{4}}
\newlabel{eq:precision}{{2.7}{4}}
\newlabel{eq:recall}{{2.8}{4}}
\newlabel{eq:f1score}{{2.9}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Confusion matrix\relax }}{5}}
\newlabel{tb:confusion_matrix}{{2.1}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Machine learning}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Supervised and unsupervised learning}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Models}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Model selection}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Deep learning}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Feedforward Neural Networks}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Convolutional Neural Networks}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Backpropagation}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Vanishing Gradient}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Batch Normalization}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Data Augmentation}{6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}TaxNet}{7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Implementation}{7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Dataset}{8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.0.1}ImageNet}{8}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{fer}
\bibdata{master_thesis}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{samuel_studies_1959}{{1}{}{{Samuel}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{11}}
